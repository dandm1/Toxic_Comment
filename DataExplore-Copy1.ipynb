{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "W2V_PATH = 'word2vec/GoogleNews-vectors-negative300.bin'\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(W2V_PATH, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127656\n",
      "31915\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0005300084f90edc</td>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00054a5e18b50dd4</td>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0006f16e4e9f292e</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00070ef96486d6f9</td>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00078f8ce7eb276d</td>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000897889268bc93</td>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0009801bd85e5806</td>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0009eaea3325de8c</td>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000b08c464718505</td>\n",
       "      <td>\"\\n\\n Regarding your recent edits \\n\\nOnce aga...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000bfd0867774845</td>\n",
       "      <td>\"\\nGood to know. About me, yeah, I'm studying ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000c0dfd995809fa</td>\n",
       "      <td>\"\\n\\n Snowflakes are NOT always symmetrical! \\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000c6a3f0cd3ba8e</td>\n",
       "      <td>\"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000cfee90f50d471</td>\n",
       "      <td>\"\\n\\nRe-considering 1st paragraph edit?\\nI don...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>000eefc67a2c930f</td>\n",
       "      <td>Radial symmetry \\n\\nSeveral now extinct lineag...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000f35deef84dc4a</td>\n",
       "      <td>There's no need to apologize. A Wikipedia arti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000ffab30195c5e1</td>\n",
       "      <td>Yes, because the mother of the child in the ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0010307a3a50a353</td>\n",
       "      <td>\"\\nOk. But it will take a bit of work but I ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0010833a96e1f886</td>\n",
       "      <td>\"== A barnstar for you! ==\\n\\n  The Real Life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127626</th>\n",
       "      <td>aa9d559a33b98c32</td>\n",
       "      <td>\"\\nPardon me for butting in, DGG, but Stifle d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127627</th>\n",
       "      <td>aa9f04bd11e52714</td>\n",
       "      <td>It seems that according to Sywlia, being Polis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127628</th>\n",
       "      <td>aaa13610d5e6b3f9</td>\n",
       "      <td>\"\\n\\n GA Shannon. \\n\\nHi, I noticed you posted...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127629</th>\n",
       "      <td>aaa222b64bd12bcd</td>\n",
       "      <td>in other words, don't use the word a s s with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127630</th>\n",
       "      <td>aaa2bf853800d7ee</td>\n",
       "      <td>Where did I attack him????? Where I only put b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127631</th>\n",
       "      <td>aaa6fb8f392b26c2</td>\n",
       "      <td>It's OK I watch here. You have good day too.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127632</th>\n",
       "      <td>aaa806e060e07269</td>\n",
       "      <td>Friday Night AHO - isn't it that time again wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127633</th>\n",
       "      <td>aaa9b599ad3d1ec8</td>\n",
       "      <td>\"Thanks for experimenting with Wikipedia. Your...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127634</th>\n",
       "      <td>aaad6f67e74ddf6a</td>\n",
       "      <td>To disrespectful and ignorant Iryna Harpy \\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127635</th>\n",
       "      <td>aab211c4b3927362</td>\n",
       "      <td>\"\\n\\nSince you also used this account for vand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127636</th>\n",
       "      <td>aab3cbbaf9d217bc</td>\n",
       "      <td>\"\\n\\n And I did read the WP:UP. It says \"\"Inap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127637</th>\n",
       "      <td>aab4f48f09abd09d</td>\n",
       "      <td>This looks like a personal essay of some kind....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127638</th>\n",
       "      <td>aab5ca96051af6e8</td>\n",
       "      <td>\"\\n\\nWhy thank you! Now I can delete  tagged a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127639</th>\n",
       "      <td>aab609048534b872</td>\n",
       "      <td>QUESTION: Why is there no section on the BBQ o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127640</th>\n",
       "      <td>aab6c9b22a135062</td>\n",
       "      <td>\"\\n\\n Having all 3 will be superbly long! Appa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127641</th>\n",
       "      <td>aab7794e6bc53f94</td>\n",
       "      <td>\"\\n\\nCite your sources and you can remove it. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127642</th>\n",
       "      <td>aab7cd350cc6e169</td>\n",
       "      <td>093 SSN \\n\\nHello Thomas. W. Thank you for you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127643</th>\n",
       "      <td>aab90b54a06dde85</td>\n",
       "      <td>You Made A Big Mistake Not As Big As Your Fath...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127644</th>\n",
       "      <td>aab97c4af3156525</td>\n",
       "      <td>\"Revisiting neutrality on the Clinton entry==\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127645</th>\n",
       "      <td>aabb67f3349f80ca</td>\n",
       "      <td>\"\\n\\n February 2009 \\n Please stop. If you con...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127646</th>\n",
       "      <td>aabd49f77d8ed94b</td>\n",
       "      <td>]]\\n Globular Cluster M107 to [[Messier 107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127647</th>\n",
       "      <td>aabdafe63157f03f</td>\n",
       "      <td>Are you sure I reverted? I was just removing N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127648</th>\n",
       "      <td>aabe6e8ab05194a4</td>\n",
       "      <td>\"\\n@Tijfo098: The issue is less your review , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127649</th>\n",
       "      <td>aabf2ad84f1c047e</td>\n",
       "      <td>9th month of 2009\\n You are crazy, spending al...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127650</th>\n",
       "      <td>aac15824e3e52d70</td>\n",
       "      <td>Latin translation needed\\n\\nI'm working on a n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127651</th>\n",
       "      <td>aac2665b5d8101c2</td>\n",
       "      <td>\"Hollywood stardom\\nWhat is meant by \"\"Despite...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127652</th>\n",
       "      <td>aac4b9af642e5e4d</td>\n",
       "      <td>We'll see about that.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127653</th>\n",
       "      <td>aac4d0cff5e12031</td>\n",
       "      <td>\"\\n Speedy deletion of \"\"27 Tricor Ave. New Pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127654</th>\n",
       "      <td>aac4dc3102e5eaad</td>\n",
       "      <td>\"\\n\\nThe additions I made were 100% factual. I...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127655</th>\n",
       "      <td>aac5fc3b2eb2a65f</td>\n",
       "      <td>Nathan, we have been through this a thousand t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127656 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "5       00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "6       0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7       00031b1e95af7921  Your vandalism to the Matt Shirvington article...   \n",
       "8       00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n",
       "9       00040093b2687caa  alignment on this subject and which are contra...   \n",
       "10      0005300084f90edc  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...   \n",
       "11      00054a5e18b50dd4  bbq \\n\\nbe a man and lets discuss it-maybe ove...   \n",
       "12      0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "13      0006f16e4e9f292e  Before you start throwing accusations and warn...   \n",
       "14      00070ef96486d6f9  Oh, and the girl above started her arguments w...   \n",
       "15      00078f8ce7eb276d  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...   \n",
       "16      0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "17      000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski   \n",
       "18      0009801bd85e5806  The Mitsurugi point made no sense - why not ar...   \n",
       "19      0009eaea3325de8c  Don't mean to bother you \\n\\nI see that you're...   \n",
       "20      000b08c464718505  \"\\n\\n Regarding your recent edits \\n\\nOnce aga...   \n",
       "21      000bfd0867774845  \"\\nGood to know. About me, yeah, I'm studying ...   \n",
       "22      000c0dfd995809fa  \"\\n\\n Snowflakes are NOT always symmetrical! \\...   \n",
       "23      000c6a3f0cd3ba8e  \"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...   \n",
       "24      000cfee90f50d471  \"\\n\\nRe-considering 1st paragraph edit?\\nI don...   \n",
       "25      000eefc67a2c930f  Radial symmetry \\n\\nSeveral now extinct lineag...   \n",
       "26      000f35deef84dc4a  There's no need to apologize. A Wikipedia arti...   \n",
       "27      000ffab30195c5e1  Yes, because the mother of the child in the ca...   \n",
       "28      0010307a3a50a353  \"\\nOk. But it will take a bit of work but I ca...   \n",
       "29      0010833a96e1f886  \"== A barnstar for you! ==\\n\\n  The Real Life ...   \n",
       "...                  ...                                                ...   \n",
       "127626  aa9d559a33b98c32  \"\\nPardon me for butting in, DGG, but Stifle d...   \n",
       "127627  aa9f04bd11e52714  It seems that according to Sywlia, being Polis...   \n",
       "127628  aaa13610d5e6b3f9  \"\\n\\n GA Shannon. \\n\\nHi, I noticed you posted...   \n",
       "127629  aaa222b64bd12bcd  in other words, don't use the word a s s with ...   \n",
       "127630  aaa2bf853800d7ee  Where did I attack him????? Where I only put b...   \n",
       "127631  aaa6fb8f392b26c2       It's OK I watch here. You have good day too.   \n",
       "127632  aaa806e060e07269  Friday Night AHO - isn't it that time again wh...   \n",
       "127633  aaa9b599ad3d1ec8  \"Thanks for experimenting with Wikipedia. Your...   \n",
       "127634  aaad6f67e74ddf6a  To disrespectful and ignorant Iryna Harpy \\n\\n...   \n",
       "127635  aab211c4b3927362  \"\\n\\nSince you also used this account for vand...   \n",
       "127636  aab3cbbaf9d217bc  \"\\n\\n And I did read the WP:UP. It says \"\"Inap...   \n",
       "127637  aab4f48f09abd09d  This looks like a personal essay of some kind....   \n",
       "127638  aab5ca96051af6e8  \"\\n\\nWhy thank you! Now I can delete  tagged a...   \n",
       "127639  aab609048534b872  QUESTION: Why is there no section on the BBQ o...   \n",
       "127640  aab6c9b22a135062  \"\\n\\n Having all 3 will be superbly long! Appa...   \n",
       "127641  aab7794e6bc53f94  \"\\n\\nCite your sources and you can remove it. ...   \n",
       "127642  aab7cd350cc6e169  093 SSN \\n\\nHello Thomas. W. Thank you for you...   \n",
       "127643  aab90b54a06dde85  You Made A Big Mistake Not As Big As Your Fath...   \n",
       "127644  aab97c4af3156525  \"Revisiting neutrality on the Clinton entry==\\...   \n",
       "127645  aabb67f3349f80ca  \"\\n\\n February 2009 \\n Please stop. If you con...   \n",
       "127646  aabd49f77d8ed94b        ]]\\n Globular Cluster M107 to [[Messier 107   \n",
       "127647  aabdafe63157f03f  Are you sure I reverted? I was just removing N...   \n",
       "127648  aabe6e8ab05194a4  \"\\n@Tijfo098: The issue is less your review , ...   \n",
       "127649  aabf2ad84f1c047e  9th month of 2009\\n You are crazy, spending al...   \n",
       "127650  aac15824e3e52d70  Latin translation needed\\n\\nI'm working on a n...   \n",
       "127651  aac2665b5d8101c2  \"Hollywood stardom\\nWhat is meant by \"\"Despite...   \n",
       "127652  aac4b9af642e5e4d                              We'll see about that.   \n",
       "127653  aac4d0cff5e12031  \"\\n Speedy deletion of \"\"27 Tricor Ave. New Pa...   \n",
       "127654  aac4dc3102e5eaad  \"\\n\\nThe additions I made were 100% factual. I...   \n",
       "127655  aac5fc3b2eb2a65f  Nathan, we have been through this a thousand t...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "5           0             0        0       0       0              0  \n",
       "6           1             1        1       0       1              0  \n",
       "7           0             0        0       0       0              0  \n",
       "8           0             0        0       0       0              0  \n",
       "9           0             0        0       0       0              0  \n",
       "10          0             0        0       0       0              0  \n",
       "11          0             0        0       0       0              0  \n",
       "12          1             0        0       0       0              0  \n",
       "13          0             0        0       0       0              0  \n",
       "14          0             0        0       0       0              0  \n",
       "15          0             0        0       0       0              0  \n",
       "16          1             0        0       0       0              0  \n",
       "17          0             0        0       0       0              0  \n",
       "18          0             0        0       0       0              0  \n",
       "19          0             0        0       0       0              0  \n",
       "20          0             0        0       0       0              0  \n",
       "21          0             0        0       0       0              0  \n",
       "22          0             0        0       0       0              0  \n",
       "23          0             0        0       0       0              0  \n",
       "24          0             0        0       0       0              0  \n",
       "25          0             0        0       0       0              0  \n",
       "26          0             0        0       0       0              0  \n",
       "27          0             0        0       0       0              0  \n",
       "28          0             0        0       0       0              0  \n",
       "29          0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "127626      0             0        0       0       0              0  \n",
       "127627      0             0        0       0       0              0  \n",
       "127628      0             0        0       0       0              0  \n",
       "127629      1             0        1       0       0              0  \n",
       "127630      0             0        0       0       0              0  \n",
       "127631      0             0        0       0       0              0  \n",
       "127632      0             0        0       0       0              0  \n",
       "127633      0             0        0       0       0              0  \n",
       "127634      0             0        0       0       1              0  \n",
       "127635      0             0        0       0       0              0  \n",
       "127636      0             0        0       0       0              0  \n",
       "127637      0             0        0       0       0              0  \n",
       "127638      0             0        0       0       0              0  \n",
       "127639      0             0        0       0       0              0  \n",
       "127640      0             0        0       0       0              0  \n",
       "127641      0             0        0       0       0              0  \n",
       "127642      0             0        0       0       0              0  \n",
       "127643      0             0        0       0       0              0  \n",
       "127644      0             0        0       0       0              0  \n",
       "127645      0             0        0       0       0              0  \n",
       "127646      0             0        0       0       0              0  \n",
       "127647      0             0        0       0       0              0  \n",
       "127648      0             0        0       0       0              0  \n",
       "127649      1             0        0       0       0              0  \n",
       "127650      0             0        0       0       0              0  \n",
       "127651      0             0        0       0       0              0  \n",
       "127652      0             0        0       0       0              0  \n",
       "127653      0             0        0       0       0              0  \n",
       "127654      1             0        0       0       1              1  \n",
       "127655      0             0        0       0       0              0  \n",
       "\n",
       "[127656 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data = pd.read_csv('data/train.csv')\n",
    "split_num = int(len(temp_data)*0.8)\n",
    "test_data = temp_data.iloc[split_num:]\n",
    "train_data = temp_data.iloc[:split_num]\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "def clean_punc(input_string):\n",
    "    proc_string = input_string.replace('<',' <less ')\n",
    "    proc_string = proc_string.replace('>',' <greater> ')\n",
    "    proc_string = re.sub(\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\",' <url> ',proc_string)\n",
    "    proc_string = proc_string.replace(' <less ',' <less> ')\n",
    "    proc_string = proc_string.replace('?',' <question> ')\n",
    "    proc_string = proc_string.replace('...',' <suspension> ')\n",
    "    proc_string = proc_string.replace('. ',' <period> ')\n",
    "    proc_string = proc_string if not proc_string.endswith('.') else proc_string[:-1]\n",
    "    proc_string = proc_string.replace('/',' <slash> ')\n",
    "    proc_string = proc_string.replace('\\\\',' <backslash> ')\n",
    "    proc_string = proc_string.replace('; ',' <semicolon> ')\n",
    "    proc_string = proc_string.replace(': ',' <colon> ')\n",
    "    proc_string = proc_string.replace(', ',' <comma> ')\n",
    "    proc_string = proc_string.replace('!',' <exclame> ')\n",
    "    proc_string = proc_string.replace('\\n',' <newline> ')\n",
    "    proc_string = proc_string.replace(' - ',' <dash> ')\n",
    "    proc_string = proc_string.replace('\"\"',' <quote> ')\n",
    "    proc_string = proc_string.replace('\"',' <quote> ')\n",
    "    proc_string = proc_string.replace('(',' <openbracket> ')\n",
    "    proc_string = proc_string.replace(')',' <closebracket> ')\n",
    "    return proc_string\n",
    "\n",
    "def clean_word(input_word):\n",
    "    out_word = input_word.lower()\n",
    "    if ( out_word.startswith(\"'\") and out_word.endswith(\"'\")):\n",
    "        out_word = out_word[1:-1]\n",
    "    \n",
    "    if len(out_word)>0:\n",
    "        out_word = out_word if not out_word[-1] in ['.',':',';',','] else out_word[:-1]\n",
    "    \n",
    "    return out_word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [clean_punc(comment) for comment in train_data.comment_text]\n",
    "comment_words = []\n",
    "for comment in comments:\n",
    "    comment_words.append ([word for word in comment.split()])\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "flat_comments = flatten(comment_words)\n",
    "\n",
    "word_counts = collections.Counter()\n",
    "for word in flat_comments:\n",
    "    word_counts[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = [clean_punc(comment) for comment in test_data.comment_text]\n",
    "test_comment_words = []\n",
    "for comment in test_comments:\n",
    "    test_comment_words.append ([word for word in comment.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = train_data.as_matrix(columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate'])\n",
    "labels_test = test_data.as_matrix(columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<comma>',\n",
       " 'the',\n",
       " '<period>',\n",
       " '<newline>',\n",
       " 'to',\n",
       " '<quote>',\n",
       " 'of',\n",
       " 'and',\n",
       " 'a',\n",
       " 'I',\n",
       " 'you',\n",
       " 'is',\n",
       " 'that',\n",
       " 'in',\n",
       " 'it',\n",
       " '<exclame>',\n",
       " 'for',\n",
       " '<closebracket>',\n",
       " 'not',\n",
       " 'on']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(word_counts))\n",
    "\n",
    "very_common = [word for word,_ in word_counts.most_common(100)]\n",
    "\n",
    "very_common[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [word for word in word_counts.keys() if word_counts[word]>4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 79.68248260951307\n",
      "5 Percentile : 7.0\n",
      "10 Percentile : 10.0\n",
      "15 Percentile : 13.0\n",
      "20 Percentile : 17.0\n",
      "25 Percentile : 20.0\n",
      "30 Percentile : 24.0\n",
      "35 Percentile : 28.0\n",
      "40 Percentile : 33.0\n",
      "45 Percentile : 37.0\n",
      "50 Percentile : 43.0\n",
      "55 Percentile : 49.0\n",
      "60 Percentile : 56.0\n",
      "65 Percentile : 64.0\n",
      "70 Percentile : 74.0\n",
      "75 Percentile : 88.0\n",
      "80 Percentile : 106.0\n",
      "85 Percentile : 134.0\n",
      "90 Percentile : 178.0\n",
      "95 Percentile : 269.0\n",
      "100 Percentile : 4950.0\n"
     ]
    }
   ],
   "source": [
    "comment_lens = [len(comment) for comment in comment_words]\n",
    "print(\"Average: {}\".format(sum(comment_lens)/float(len(comment_lens))))\n",
    "for perc in range(5,101,5):\n",
    "    print(\"{0} Percentile : {1}\".format(perc,np.percentile(comment_lens,perc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'wikipedia' in w2v.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_word(in_word):\n",
    "    out_vector = np.zeros(307)\n",
    "    if in_word.isupper():\n",
    "        out_vector[300] = 1 #Flag shouting\n",
    "    if in_word.islower():\n",
    "        out_vector[301] = 1 #Flag normal text\n",
    "    work_word = in_word.lower()\n",
    "    if work_word in very_common:\n",
    "        out_vector[302] = 1 #Flag 100 most common words\n",
    "    \n",
    "    if work_word[0] == '<':\n",
    "        out_vector[303] = 1 #Flag punctuation we replaced and return\n",
    "        return out_vector\n",
    "    \n",
    "    if work_word in w2v.vocab and work_word in filtered_words:\n",
    "        out_vector[:300] = w2v[work_word]\n",
    "        return out_vector\n",
    "    \n",
    "    if work_word[0] == work_word[-1] and work_word[0] in ['_','*',\"'\"]:\n",
    "        out_vector[304] = 1 #Flag words with emphasis\n",
    "        work_word = work_word[1:-1]\n",
    "    \n",
    "    if len(work_word)>0:\n",
    "        work_word = work_word if not work_word[-1] in ['.',':',';',',',\"'\"] else work_word[:-1]\n",
    "\n",
    "    if work_word in w2v.vocab and work_word in filtered_words:\n",
    "        out_vector[:300] = w2v[work_word]\n",
    "        return out_vector\n",
    "    \n",
    "    out_vector[305] = 1 #Flag unknown words\n",
    "    return out_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21875    -0.12207031 -0.00296021  0.02429199  0.08300781 -0.01977539\n",
      "  0.00396729 -0.09570312  0.11035156 -0.37109375  0.12451172 -0.54296875\n",
      " -0.09912109  0.08544922 -0.16894531 -0.10205078  0.22753906 -0.07421875\n",
      " -0.03015137 -0.35742188 -0.11523438 -0.01171875  0.27148438 -0.01049805\n",
      " -0.22070312 -0.17578125 -0.18847656  0.18554688 -0.08007812 -0.05615234\n",
      " -0.05151367 -0.11132812 -0.24609375 -0.09912109 -0.14550781  0.08447266\n",
      " -0.12792969  0.29882812  0.24609375  0.10449219  0.12402344 -0.07324219\n",
      "  0.15625     0.59765625  0.28125     0.00970459 -0.171875   -0.25585938\n",
      " -0.24511719 -0.171875   -0.24121094 -0.10302734 -0.17578125 -0.05834961\n",
      "  0.18945312 -0.08349609  0.11279297  0.07470703 -0.27148438 -0.3203125\n",
      "  0.12158203 -0.04052734  0.13378906 -0.18457031  0.01904297 -0.19433594\n",
      " -0.203125   -0.24414062  0.16113281  0.02490234 -0.11035156  0.16015625\n",
      " -0.23632812 -0.19628906 -0.14550781  0.10546875  0.07177734 -0.14257812\n",
      " -0.03857422  0.20703125  0.30078125  0.06591797  0.14160156 -0.09228516\n",
      "  0.3125      0.09667969  0.04296875  0.31640625  0.19726562  0.04272461\n",
      " -0.04833984 -0.09228516 -0.26757812 -0.11914062  0.03710938  0.26367188\n",
      " -0.01989746  0.01098633  0.30273438  0.24902344 -0.2890625   0.18945312\n",
      " -0.01281738  0.07714844  0.07714844  0.21875    -0.59765625 -0.1015625\n",
      "  0.09863281 -0.11523438 -0.40625     0.01867676 -0.05859375 -0.125\n",
      "  0.109375   -0.08007812 -0.17871094 -0.29296875  0.19726562  0.10449219\n",
      "  0.16113281 -0.33398438 -0.22558594 -0.10791016 -0.11230469  0.07910156\n",
      " -0.20214844  0.03637695 -0.13378906 -0.0037384  -0.41015625 -0.18652344\n",
      " -0.08984375  0.26367188 -0.1953125  -0.27929688 -0.31835938 -0.02246094\n",
      " -0.25585938  0.01544189  0.10546875 -0.09960938  0.01660156 -0.00756836\n",
      "  0.02514648 -0.18847656 -0.09082031 -0.14648438 -0.04956055 -0.30664062\n",
      "  0.14453125 -0.15820312 -0.33398438 -0.05615234 -0.1328125  -0.18066406\n",
      "  0.16503906  0.00177765 -0.15527344 -0.16601562  0.08203125  0.34375\n",
      " -0.33203125 -0.2421875   0.30664062 -0.26171875  0.15136719  0.17285156\n",
      " -0.47851562  0.03564453  0.01806641  0.01556396  0.13769531  0.00169373\n",
      " -0.00897217  0.04882812 -0.07421875 -0.53515625  0.6328125  -0.18164062\n",
      "  0.04516602 -0.21679688 -0.32226562  0.07177734  0.203125    0.12597656\n",
      " -0.17382812  0.20117188 -0.1484375   0.06738281  0.16308594  0.01916504\n",
      " -0.15722656 -0.21972656  0.26757812  0.265625   -0.27929688 -0.38085938\n",
      " -0.0703125  -0.14648438 -0.09521484  0.2734375   0.04833984  0.11669922\n",
      " -0.05566406  0.04296875  0.04150391 -0.15429688 -0.46679688  0.22460938\n",
      " -0.06835938  0.10302734 -0.3125      0.08154297 -0.12597656  0.18359375\n",
      "  0.10791016  0.03112793  0.17578125 -0.01287842  0.04077148 -0.19335938\n",
      "  0.24121094  0.13183594  0.12304688  0.1796875   0.12353516  0.27148438\n",
      "  0.08300781  0.26171875  0.14355469 -0.07226562 -0.04467773 -0.01831055\n",
      "  0.07226562  0.16894531  0.14160156  0.00646973  0.28125    -0.09570312\n",
      "  0.296875    0.07714844  0.07226562 -0.16894531 -0.01446533  0.18554688\n",
      " -0.01495361  0.55078125 -0.12890625 -0.06982422  0.06689453  0.12988281\n",
      "  0.17480469  0.02197266  0.06225586 -0.33984375 -0.37109375  0.1796875\n",
      "  0.11425781 -0.13378906  0.3984375  -0.02685547  0.11035156 -0.25976562\n",
      "  0.2890625   0.08984375 -0.05004883 -0.20605469 -0.0222168  -0.34375\n",
      " -0.17382812  0.07324219  0.14550781  0.11376953 -0.06030273 -0.11035156\n",
      "  0.21191406 -0.20703125  0.0168457   0.3359375   0.23925781  0.4140625\n",
      " -0.41015625  0.18261719  0.08642578 -0.12207031 -0.02758789  0.27929688\n",
      " -0.03295898  0.14550781  0.32226562  0.10205078 -0.17578125  0.37304688\n",
      " -0.09179688 -0.14257812 -0.00221252 -0.35351562 -0.25195312 -0.11621094\n",
      "  1.          0.          0.          0.          1.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(map_word('*WIKIPEDIA*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_comment(input_comment):\n",
    "    result_matrix = np.zeros((250,307))\n",
    "    if (len(input_comment) == 0):\n",
    "        return result_matrix\n",
    "    \n",
    "    input_comment = input_comment[:250]\n",
    "    temp_matrix = [map_word(word) for word in input_comment]\n",
    "    result_matrix[-len(input_comment):,:] = temp_matrix\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 307)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the process comment function\n",
    "np.array(process_comment(comment_words[21])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach with pre-encoded Features\n",
    "\n",
    "Doesn't work unfortunately - not nearly enough memory for that. So disabled."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_features = []\n",
    "processed = 0\n",
    "for one_comment in comment_words:\n",
    "    train_features.append(process_comment(one_comment))\n",
    "    processed += 1\n",
    "    if ( processed % 1000 ) == 0:\n",
    "        print('Processed {0} of {1} train features:'.format(processed,len(comment_words)))\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "\n",
    "np.savez_compressed('train_features',features=train_features,labels=train_labels)\n",
    "\n",
    "train_features = None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test_features = []\n",
    "processed = 0\n",
    "for one_comment in test_comment_words:\n",
    "    test_features.append(process_comment(one_comment))\n",
    "    processed += 1\n",
    "    if ( processed % 100 ) == 0:\n",
    "        print('Processed {0} of {1} test features:'.format(processed,len(test_comment_words)))\n",
    "\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "np.savez_compressed('test_features',features=test_features,labels=test_labels)\n",
    "\n",
    "test_features = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Approach using live generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def get_batches(comment_words,labels,batch_size):\n",
    "    \n",
    "    num_inputs = len(comment_words)\n",
    "    num_batches = num_inputs//batch_size\n",
    "    \n",
    "    labels_true = []\n",
    "    offset = []\n",
    "    for i in range(0,6):\n",
    "        labels_true.append([])\n",
    "        offset.append(0)\n",
    "\n",
    "    for i,label in enumerate(labels):\n",
    "        for ii in range(0,6):\n",
    "            if label[ii] == 1:\n",
    "                labels_true[ii].append(i)\n",
    "    \n",
    "    no_labels = [i for i,label in enumerate(labels) if sum(label)==0]\n",
    "    shuffle(no_labels)\n",
    "    \n",
    "    offset.append(0)\n",
    "    group_size = batch_size // 8\n",
    "    \n",
    "    for ii in range(0,num_batches):\n",
    "        indicies = set()\n",
    "        for i in range(0,6):\n",
    "            for iii in range(0,group_size):\n",
    "                indicies.add(labels_true[i][offset[i]])\n",
    "                offset[i]+=1\n",
    "                if (offset[i]==len(labels_true[i])):\n",
    "                    offset[i]=0\n",
    "                    shuffle(labels_true[i])\n",
    "                \n",
    "        num_remaining = batch_size - len(indicies)\n",
    "        for iii in range(0,num_remaining):\n",
    "            indicies.add(no_labels[offset[6]])\n",
    "            offset[6]+=1\n",
    "            if offset[6] == len(no_labels):\n",
    "                offset[6]=0\n",
    "                shuffle(no_labels)\n",
    "            \n",
    "        features = []\n",
    "        for iii in indicies:\n",
    "            features.append(process_comment(comment_words[iii]))\n",
    "        \n",
    "        return_labels = [[max(labels[i]) for i in indicies]]\n",
    "        yield features, return_labels\n",
    "\n",
    "def get_test_batches(comment_words,labels,batch_size):\n",
    "    num_inputs = len(comment_words)\n",
    "    num_batches = num_inputs//batch_size\n",
    "\n",
    "    for ii in range(0,num_batches):\n",
    "        end = ii * batch_size + batch_size if ii * batch_size + batch_size <= num_inputs else num_inputs - 1\n",
    "        indicies = range(ii * batch_size,end)\n",
    "        features = []\n",
    "        for iii in indicies:\n",
    "            features.append(process_comment(comment_words[iii]))\n",
    "        \n",
    "        return_labels = [[max(labels[i]) for i in indicies]]\n",
    "        yield features, return_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = []\n",
    "for i in range(0,6):\n",
    "    labels_true.append([])\n",
    "\n",
    "for i,label in enumerate(labels_train):\n",
    "    for ii in range(0,6):\n",
    "        if label[ii] == 1:\n",
    "            labels_true[ii].append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12257, 1284, 6780, 386, 6295, 1100]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(the_list) for the_list in labels_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-paramters\n",
    "layer_size = 512\n",
    "layer_count = 1\n",
    "keep_prob_training = 0.6\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size=128\n",
    "comment_length = 250\n",
    "embed_size = 307\n",
    "n_labels = 1\n",
    "checkpoint_path = 'cpa2n9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a graph and placeholders\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32,[batch_size,comment_length,embed_size],name='inputs')\n",
    "    labels_ = tf.placeholder(tf.float32,[None,None],name='outputs')\n",
    "    keep_prob_ = tf.placeholder(tf.float32,name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the network\n",
    "with graph.as_default():\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=layer_size,activation=tf.tanh)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell,input_keep_prob=keep_prob_)\n",
    "    network = drop\n",
    "    for _ in range(layer_count):\n",
    "        network = tf.contrib.rnn.MultiRNNCell([network])\n",
    "\n",
    "    initial_state = network.zero_state(batch_size,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "with graph.as_default():\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(network,inputs_,initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get outputs\n",
    "with graph.as_default():\n",
    "    predictions = tf.contrib.layers.flatten(outputs)\n",
    "    predictions = tf.contrib.layers.fully_connected(predictions, n_labels, activation_fn=tf.sigmoid)\n",
    "    cost = tf.losses.log_loss(labels_, predictions)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine accuracy on test set\n",
    "with graph.as_default():\n",
    "    validation_metrics_var_scope = \"validation_metrics\"\n",
    "    binary_pred = tf.cast(tf.round(predictions), tf.bool)\n",
    "    binary_labels = tf.cast(labels_, tf.bool)\n",
    "    correct_pos = tf.reduce_sum(tf.cast(tf.logical_and(binary_pred,binary_labels),tf.int32))\n",
    "    false_pos = tf.reduce_sum(tf.cast(tf.logical_and(binary_pred,tf.logical_not(binary_labels)),tf.int32))\n",
    "    false_neg = tf.reduce_sum(tf.cast(tf.logical_and(tf.logical_not(binary_pred),binary_labels),tf.int32))\n",
    "    correct_neg = tf.reduce_sum(tf.cast(tf.logical_and(tf.logical_not(binary_pred),tf.logical_not(binary_labels)),tf.int32))\n",
    "    auc = tf.metrics.auc(labels=labels_,predictions=predictions,name=validation_metrics_var_scope)\n",
    "    accuracy = tf.metrics.accuracy(labels=labels_,predictions=predictions,name=validation_metrics_var_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Epoch: 0/20 Iteration: 200/19940 Train loss: 0.564\n",
      "During epoch 0\n",
      "  Val acc      : 0.0\n",
      "  AuC          : 0.47018536925315857\n",
      "  Correct pos  : 14208\n",
      "  False neg    :     0\n",
      "  Correct neg  :     0\n",
      "  False pos    : 116864\n",
      "\n",
      "Epoch: 0/20 Iteration: 320/19940 Train loss: 0.562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-540aaf1d3f75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             feed = {inputs_:x,\n\u001b[1;32m     31\u001b[0m                     \u001b[0mlabels_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-2482c15be508>\u001b[0m in \u001b[0;36mget_batches\u001b[0;34m(comment_words, labels, batch_size)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindicies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_comment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mreturn_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindicies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ce48b52b6433>\u001b[0m in \u001b[0;36mprocess_comment\u001b[0;34m(input_comment)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_comment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_comment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtemp_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmap_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_comment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresult_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_comment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ce48b52b6433>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_comment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_comment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtemp_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmap_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_comment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresult_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_comment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-927d935f33be>\u001b[0m in \u001b[0;36mmap_word\u001b[0;34m(in_word)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mwork_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwork_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mout_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwork_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "n_batches = len(comment_words)//batch_size\n",
    "\n",
    "val_acc = []\n",
    "false_pos_list = []\n",
    "\n",
    "last_checkpoint = tf.train.latest_checkpoint(checkpoint_path)\n",
    "\n",
    "print(\"Starting...\")\n",
    "\n",
    "iteration = 0\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    validation_metrics_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=validation_metrics_var_scope)\n",
    "    validation_metrics_init_op = tf.variables_initializer(var_list=validation_metrics_vars, name='validation_metrics_init')\n",
    "    sess.run(validation_metrics_init_op)\n",
    "    \n",
    "    if last_checkpoint != None:\n",
    "        saver.restore(sess,last_checkpoint)\n",
    "        print(\"Restored checkpoint from {}.\".format(last_checkpoint))    \n",
    "    \n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "            \n",
    "        for ii,(x,y) in enumerate(get_batches(comment_words,labels_train,batch_size),1):\n",
    "            feed = {inputs_:x,\n",
    "                    labels_:y,\n",
    "                    keep_prob_:keep_prob_training,\n",
    "                    initial_state:state}\n",
    "            \n",
    "            loss, state, _ = sess.run([cost,final_state,optimizer],feed_dict=feed)\n",
    "            iteration += 1\n",
    "            \n",
    "            if iteration%10==0:\n",
    "                print(\"\\rEpoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}/{}\".format(iteration, n_batches*epochs),\n",
    "                      \"Train loss: {:.3f}\".format(loss),end='')\n",
    "\n",
    "            if iteration%200==0:\n",
    "                val_acc.clear()\n",
    "                false_pos_list.clear()\n",
    "                total_correct_pos = 0\n",
    "                total_false_pos = 0\n",
    "                total_correct_neg = 0\n",
    "                total_false_neg = 0\n",
    "                \n",
    "                val_state = sess.run(initial_state)\n",
    "                sess.run(validation_metrics_init_op)\n",
    "                if iteration%2000==0:\n",
    "                    test_subset_x,test_subset_y = test_comment_words,labels_test\n",
    "                else:\n",
    "                    test_subset_x,test_subset_y = test_comment_words[:1024],labels_test[:1024]\n",
    "                \n",
    "                for x, y in get_test_batches(test_subset_x, test_subset_y, batch_size):\n",
    "                    feed = {inputs_: x,\n",
    "                            labels_: y,\n",
    "                            keep_prob_: 1,\n",
    "                            initial_state: val_state}\n",
    "                    \n",
    "                    auc_val, batch_acc, n_correct_pos, n_correct_neg, n_false_pos, n_false_neg, val_state = sess.run([auc, accuracy, correct_pos, correct_neg, false_pos, false_neg, final_state], feed_dict=feed)\n",
    "                    \n",
    "                    val_acc.append(batch_acc)\n",
    "                    auc_value = auc_val[1]\n",
    "                    total_correct_pos += n_correct_pos\n",
    "                    total_false_pos += n_false_pos\n",
    "                    total_correct_neg += n_correct_neg\n",
    "                    total_false_neg += n_false_neg\n",
    "                print(\"\\nDuring epoch {}\".format(e))\n",
    "                print(\"  Val acc      : {}\".format(np.mean(val_acc)))\n",
    "                print(\"  AuC          : {}\".format(auc_value))\n",
    "                #print(\"  Correct pos  : {}\".format('  '.join(['{:5}'.format(x) for x in total_correct_pos])))\n",
    "                #print(\"  False neg    : {}\".format('  '.join(['{:5}'.format(x) for x in total_false_neg])))\n",
    "                #print(\"  Correct neg  : {}\".format('  '.join(['{:5}'.format(x) for x in total_correct_neg])))\n",
    "                #print(\"  False pos    : {}\\n\".format('  '.join(['{:5}'.format(x) for x in total_false_pos])))\n",
    "                print(\"  Correct pos  : {:5}\".format(total_correct_pos))\n",
    "                print(\"  False neg    : {:5}\".format(total_false_neg))\n",
    "                print(\"  Correct neg  : {:5}\".format(total_correct_neg))\n",
    "                print(\"  False pos    : {:5}\\n\".format(total_false_pos))\n",
    "                \n",
    "                \n",
    "                saver.save(sess, \"{}/epoch{}iter{}.ckpt\".format(checkpoint_path,e,iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([labels for labels in labels_train if sum(labels)>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(labels_test[:1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
